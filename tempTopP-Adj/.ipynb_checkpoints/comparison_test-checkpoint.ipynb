{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d5b85e9",
   "metadata": {},
   "source": [
    "## Test for \"Generate 50 design solutions...\" vs. \"Generate 25 design solutions...\" vs. \"Generate 5 design solutions...\"\n",
    "\n",
    "This was all done for the prompt sequence of:\n",
    "\"Generate [X number] of design solutions for lightweight exercise device that can be used while traveling.\"\n",
    "\n",
    "Note, generate 50... just generated 50 design solutions directly.\n",
    "\n",
    "Generate 25 design solutions --> Generate 25 more design solutions for a total of 50 design solutions.\n",
    "\n",
    "Generate 5.. just followed our methodology in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6271ef41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\anaconda3\\envs\\research\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from scipy.spatial import ConvexHull\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b9abf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "922007ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convexhull(x, n_components):\n",
    "    pca = PCA(n_components = n_components)\n",
    "    reduced_data = pca.fit_transform(x)\n",
    "    explained_ratio = pca.explained_variance_ratio_\n",
    "    hull = ConvexHull(reduced_data)\n",
    "    volume = hull.volume\n",
    "    return volume, explained_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a81b621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_change(values):\n",
    "    lst = []\n",
    "    for i in range(len(values)):\n",
    "        percent_change = ((values[i] - values[len(values)-1])/abs(values[len(values)-1]))*100\n",
    "        lst.append(round(percent_change))\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8d07240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DPP_diversity(x, lambda0=0):\n",
    "    x = tf.convert_to_tensor(x, dtype='float32')\n",
    "    \n",
    "    # Normalize the rows of x to have unit norm, which is required for cosine similarity\n",
    "    x_normalized = tf.linalg.normalize(x, axis=1)[0]\n",
    "    \n",
    "    # Compute the cosine similarity matrix\n",
    "    S = tf.matmul(x_normalized, tf.transpose(x_normalized))\n",
    "    \n",
    "    # Transform cosine similarity values to be non-negative\n",
    "    S_non_negative = (S + 1.0) / 2.0\n",
    "    \n",
    "    # Create a vector of ones with the same length as the number of points in x\n",
    "    y = tf.ones(np.shape(x)[0])\n",
    "    \n",
    "    # Compute the outer product of y with itself, resulting in a matrix of Q where all elements are equal to 1\n",
    "    Q = tf.tensordot(tf.expand_dims(y, 1), tf.expand_dims(y, 0), 1)\n",
    "    if lambda0 == 0:\n",
    "        L = S_non_negative\n",
    "    else:\n",
    "        L= S*tf.math.pow(Q, lambda0)\n",
    "    # Compute the eigenvalues of L\n",
    "    eig_val, _  = tf.linalg.eigh(L)\n",
    "    # compute the log-determinant of L using the eigenvalues\n",
    "    log_det_L = -tf.reduce_mean(tf.math.log(tf.math.maximum(eig_val, 1e-7)))\n",
    "    return log_det_L.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1a47ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_centroid(embeddings):\n",
    "    distances = []\n",
    "    for i in range(embeddings.shape[0]):\n",
    "        pca = PCA(n_components = 20)\n",
    "        embeddings = pca.fit_transform(embeddings)\n",
    "        mean = np.mean(embeddings[i])\n",
    "        dist = np.sqrt(np.sum(np.square(np.subtract(embeddings[i], mean))))\n",
    "        distances.append(dist)\n",
    "    return np.mean(np.array(distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2c41754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2_vectorized(X, Y):\n",
    "    #Vectorize L2 calculation using x^2+y^2-2xy\n",
    "    X_sq = np.sum(np.square(X), axis=1)\n",
    "    Y_sq = np.sum(np.square(Y), axis=1)\n",
    "    sq = np.add(np.expand_dims(X_sq, axis=-1), np.transpose(Y_sq)) - 2*np.matmul(X,np.transpose(Y))\n",
    "    sq = np.clip(sq, 0.0, 1e12)\n",
    "    return np.sqrt(sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd0e2c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance(X, Y, distance=\"Euclidean\"):\n",
    "    if distance==\"Euclidean\":\n",
    "        return L2_vectorized(X,Y)\n",
    "    else:\n",
    "        raise Exception(\"Unknown distance metric specified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b10f97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_gen_distance(embeddings, reduction):\n",
    "    x = embeddings\n",
    "    res = calc_distance(x, x, distance = \"Euclidean\")\n",
    "    # this sets the diagonal of the matrix to the maximum of elements across the column dimension (axis = 1)\n",
    "    res = tf.linalg.set_diag(res, tf.reduce_max(res, axis=1))\n",
    "    # pick the smallest values along the columns\n",
    "    if reduction == \"min\":\n",
    "        scores = tf.reduce_min(res, axis=1)\n",
    "    # pick the average value along the columns\n",
    "    elif reduction == \"ave\":\n",
    "        scores = tf.reduce_mean(res, axis=1)\n",
    "    else:\n",
    "        raise Exception(\"Unknown reduction method\")\n",
    "    return np.mean(scores.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cd320a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of CSV files\n",
    "csv_files = [\n",
    "    'data/reviewer_test_case.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7163149a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_1_DPP = {}\n",
    "dict_1_convex = {}\n",
    "dict_1_centroid = {}\n",
    "dict_1_nearest = {}\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    count = 0\n",
    "    for column in df.columns:\n",
    "        # encode the column text data into embeddings\n",
    "        embeddings = model.encode(df[column].astype(str).tolist())\n",
    "        # calculate the DPP\n",
    "        dict_1_DPP[(csv_file, count)] = DPP_diversity(embeddings, lambda0=0)\n",
    "        # calculate the convex hull\n",
    "        dict_1_convex[(csv_file, count)] = convexhull(embeddings, n_components = 13)\n",
    "        # calculate the distance to centroid\n",
    "        dict_1_centroid[(csv_file, count)] = distance_to_centroid(embeddings)\n",
    "        # calculate the nearest generated distance (average)\n",
    "        dict_1_nearest[(csv_file, count)] = gen_gen_distance(embeddings, reduction = \"ave\")\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09c0d92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note order goes (50-design/25-design/5-design)\n",
      "\n",
      "data/reviewer_test_case.csv\n",
      "Percent difference for data/reviewer_test_case.csv:[3, -3, 0]\n"
     ]
    }
   ],
   "source": [
    "# DPP percent difference calculation\n",
    "percent_diff = {}\n",
    "for key, value in dict_1_DPP.items():\n",
    "    csv_file = key[0]\n",
    "    if csv_file not in percent_diff:\n",
    "        percent_diff[csv_file] = []\n",
    "    percent_diff[csv_file].append(value)\n",
    "\n",
    "print(\"Note order goes (50-design/25-design/5-design)\" )\n",
    "print(\"\")\n",
    "for csv_file, values in percent_diff.items():\n",
    "    percent_changes = percent_change(values)\n",
    "    print(csv_file)\n",
    "    print(f\"Percent difference for {csv_file}:{percent_changes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "689919d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note order goes (50-design/25-design/5-design)\n",
      "\n",
      "Percent difference for data/reviewer_test_case.csv:[-3, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "# Nearest Generated Difference percent difference calculation\n",
    "percent_diff = {}\n",
    "for key, value in dict_1_nearest.items():\n",
    "    csv_file = key[0]\n",
    "    if csv_file not in percent_diff:\n",
    "        percent_diff[csv_file] = []\n",
    "    percent_diff[csv_file].append(value)\n",
    "\n",
    "print(\"Note order goes (50-design/25-design/5-design)\")\n",
    "print(\"\")\n",
    "for csv_file, values in percent_diff.items():\n",
    "    percent_changes = percent_change(values)\n",
    "    print(f\"Percent difference for {csv_file}:{percent_changes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9477a769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note order goes (50-design/25-design/5-design)\n",
      "\n",
      "Percent difference for data/reviewer_test_case.csv:[-4, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Nearest Generated Difference percent difference calculation\n",
    "percent_diff = {}\n",
    "for key, value in dict_1_centroid.items():\n",
    "    csv_file = key[0]\n",
    "    if csv_file not in percent_diff:\n",
    "        percent_diff[csv_file] = []\n",
    "    percent_diff[csv_file].append(value)\n",
    "\n",
    "print(\"Note order goes (50-design/25-design/5-design)\")\n",
    "print(\"\")\n",
    "for csv_file, values in percent_diff.items():\n",
    "    percent_changes = percent_change(values)\n",
    "    print(f\"Percent difference for {csv_file}:{percent_changes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7708da27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note order goes (50-design/25-design/5-design)\n",
      "\n",
      "Percent difference for data/reviewer_test_case.csv:[-30, -16, 0]\n"
     ]
    }
   ],
   "source": [
    "# Nearest Generated Difference percent difference calculation\n",
    "percent_diff = {}\n",
    "for key, value in dict_1_convex.items():\n",
    "    csv_file = key[0]\n",
    "    value1 = value[0]\n",
    "    if csv_file not in percent_diff:\n",
    "        percent_diff[csv_file] = []\n",
    "    percent_diff[csv_file].append(value1)\n",
    "\n",
    "print(\"Note order goes (50-design/25-design/5-design)\")\n",
    "print(\"\")\n",
    "for csv_file, values in percent_diff.items():\n",
    "    percent_changes = percent_change(values)\n",
    "    print(f\"Percent difference for {csv_file}:{percent_changes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcb2977",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:research]",
   "language": "python",
   "name": "conda-env-research-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
