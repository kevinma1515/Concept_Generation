{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5484e3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from scipy.spatial import ConvexHull\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f17cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4d9eae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convexhull(x, n_components):\n",
    "    pca = PCA(n_components = n_components)\n",
    "    reduced_data = pca.fit_transform(x)\n",
    "    explained_ratio = pca.explained_variance_ratio_\n",
    "    hull = ConvexHull(reduced_data)\n",
    "    volume = hull.volume\n",
    "    return volume, explained_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ddc01c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_change(values):\n",
    "    lst = []\n",
    "    for i in range(len(values)):\n",
    "        percent_change = ((values[i] - values[len(values)-1])/abs(values[len(values)-1]))*100\n",
    "        lst.append(round(percent_change))\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9e0475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DPP_diversity(x, lambda0=0):\n",
    "    x = tf.convert_to_tensor(x, dtype='float32')\n",
    "    \n",
    "    # Normalize the rows of x to have unit norm, which is required for cosine similarity\n",
    "    x_normalized = tf.linalg.normalize(x, axis=1)[0]\n",
    "    \n",
    "    # Compute the cosine similarity matrix\n",
    "    S = tf.matmul(x_normalized, tf.transpose(x_normalized))\n",
    "    \n",
    "    # Transform cosine similarity values to be non-negative\n",
    "    S_non_negative = (S + 1.0) / 2.0\n",
    "    \n",
    "    # Create a vector of ones with the same length as the number of points in x\n",
    "    y = tf.ones(np.shape(x)[0])\n",
    "    \n",
    "    # Compute the outer product of y with itself, resulting in a matrix of Q where all elements are equal to 1\n",
    "    Q = tf.tensordot(tf.expand_dims(y, 1), tf.expand_dims(y, 0), 1)\n",
    "    if lambda0 == 0:\n",
    "        L = S_non_negative\n",
    "    else:\n",
    "        L= S*tf.math.pow(Q, lambda0)\n",
    "    # Compute the eigenvalues of L\n",
    "    eig_val, _  = tf.linalg.eigh(L)\n",
    "    # compute the log-determinant of L using the eigenvalues\n",
    "    log_det_L = -tf.reduce_mean(tf.math.log(tf.math.maximum(eig_val, 1e-7)))\n",
    "    return log_det_L.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8652a475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_centroid(embeddings):\n",
    "    distances = []\n",
    "    for i in range(embeddings.shape[0]):\n",
    "        pca = PCA(n_components = 20)\n",
    "        embeddings = pca.fit_transform(embeddings)\n",
    "        mean = np.mean(embeddings[i])\n",
    "        dist = np.sqrt(np.sum(np.square(np.subtract(embeddings[i], mean))))\n",
    "        distances.append(dist)\n",
    "    return np.mean(np.array(distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5316e191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2_vectorized(X, Y):\n",
    "    #Vectorize L2 calculation using x^2+y^2-2xy\n",
    "    X_sq = np.sum(np.square(X), axis=1)\n",
    "    Y_sq = np.sum(np.square(Y), axis=1)\n",
    "    sq = np.add(np.expand_dims(X_sq, axis=-1), np.transpose(Y_sq)) - 2*np.matmul(X,np.transpose(Y))\n",
    "    sq = np.clip(sq, 0.0, 1e12)\n",
    "    return np.sqrt(sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d92655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance(X, Y, distance=\"Euclidean\"):\n",
    "    if distance==\"Euclidean\":\n",
    "        return L2_vectorized(X,Y)\n",
    "    else:\n",
    "        raise Exception(\"Unknown distance metric specified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dd6fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_gen_distance(embeddings, reduction):\n",
    "    x = embeddings\n",
    "    res = calc_distance(x, x, distance = \"Euclidean\")\n",
    "    # this sets the diagonal of the matrix to the maximum of elements across the column dimension (axis = 1)\n",
    "    res = tf.linalg.set_diag(res, tf.reduce_max(res, axis=1))\n",
    "    # pick the smallest values along the columns\n",
    "    if reduction == \"min\":\n",
    "        scores = tf.reduce_min(res, axis=1)\n",
    "    # pick the average value along the columns\n",
    "    elif reduction == \"ave\":\n",
    "        scores = tf.reduce_mean(res, axis=1)\n",
    "    else:\n",
    "        raise Exception(\"Unknown reduction method\")\n",
    "    return np.mean(scores.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e344e885",
   "metadata": {},
   "source": [
    "## RQ1:\n",
    "\n",
    "(1a) How do parameters such as temperature and Top P affect the quality and diversity of the generated text output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "554beefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of CSV files\n",
    "csv_files = [\n",
    "    'data/ablation_tempTopP_froth.csv',\n",
    "    'data/ablation_tempTopP_towels.csv',\n",
    "    'data/ablation_tempTopP_time.csv',\n",
    "    'data/ablation_tempTopP_powder.csv',\n",
    "    'data/ablation_tempTopP_exercise.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99004e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this only needs to be ran once.\n",
    "dict_1_DPP = {}\n",
    "#dict_1_convex = {}\n",
    "#dict_1_centroid = {}\n",
    "#dict_1_nearest = {}\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    count = 0\n",
    "    for column in df.columns:\n",
    "        # encode the column text data into embeddings\n",
    "        embeddings = model.encode(df[column].astype(str).tolist())\n",
    "        # calculate the DPP\n",
    "        dict_1_DPP[(csv_file, count)] = DPP_diversity(embeddings, lambda0=0)\n",
    "        # calculate the convex hull\n",
    "        #dict_1_convex[(csv_file, count)] = convexhull(embeddings, n_components = 13)\n",
    "        # calculate the distance to centroid\n",
    "        #dict_1_centroid[(csv_file, count)] = distance_to_centroid(embeddings)\n",
    "        # calculate the nearest generated distance (average)\n",
    "        #dict_1_nearest[(csv_file, count)] = gen_gen_distance(embeddings, reduction = \"ave\")\n",
    "        count += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1814c15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DPP\n",
    "# convert tuples in dictionary to strings\n",
    "dict_1_DPP_str = {str(key): value for key, value in dict_1_DPP.items()}\n",
    "\n",
    "# convert float32 values to float\n",
    "dict_1_DPP_str = {key:float(value) for key, value in dict_1_DPP_str.items()}\n",
    "\n",
    "with open(\"data/DPP_TempTopP.json\", \"w\") as file:\n",
    "    json.dump(dict_1_DPP_str, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dec92fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dictionary results into a json file\n",
    "    \n",
    "# Centroid Distance\n",
    "dict_1_centroid_str = {str(key): value for key, value in dict_1_centroid.items()}\n",
    "\n",
    "dict_1_centroid_str = {key:float(value) for key, value in dict_1_centroid_str.items()}\n",
    "\n",
    "with open(\"data/centroid_TempTopP.json\", \"w\") as file:\n",
    "    json.dump(dict_1_centroid_str, file)\n",
    "    \n",
    "# Nearest Generated Sample\n",
    "dict_1_nearest_str = {str(key): value for key, value in dict_1_nearest.items()}\n",
    "\n",
    "dict_1_nearest_str = {key:float(value) for key, value in dict_1_nearest_str.items()}\n",
    "\n",
    "with open(\"data/nearest_TempTopP.json\", \"w\") as file:\n",
    "    json.dump(dict_1_nearest_str, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6db62273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to retrieve the json file\n",
    "with open(\"data/DPP_TempTopP.json\", \"r\") as file:\n",
    "    dict_1_DPP_json = json.load(file)\n",
    "dict_1_DPP_json = {eval(key): value for key, value in dict_1_DPP_json.items()}\n",
    "\n",
    "with open(\"data/centroid_TempTopP.json\", \"r\") as file:\n",
    "    dict_1_centroid_json = json.load(file)\n",
    "dict_1_centroid_json = {eval(key): value for key, value in dict_1_centroid_json.items()}\n",
    "\n",
    "with open(\"data/nearest_TempTopP.json\", \"r\") as file:\n",
    "    dict_1_nearest_json = json.load(file)\n",
    "dict_1_nearest_json = {eval(key): value for key, value in dict_1_nearest_json.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53d1591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convex hull is a bit trickier...\n",
    "\n",
    "# Convert tuples and arrays to compatible format\n",
    "# custom conversion function that converts tuples to a dictionary with a special key and arrays\n",
    "# to a dictionary with a special key\n",
    "def convert_to_json(obj):\n",
    "    if isinstance(obj, tuple):\n",
    "        return {'__tuple__': True, 'items': list(obj)}\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return {'__ndarray__': True, 'n_component': obj.tolist()}\n",
    "    return obj\n",
    "\n",
    "\n",
    "dict_1_convex_str = {str(key): value for key, value in dict_1_convex.items()}\n",
    "\n",
    "with open(\"data/convex_TempTopP.json\", \"w\") as file:\n",
    "    json.dump(dict_1_convex_str, file, default = convert_to_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "698b7870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert convex hull back to the original dictionary with tuples and numpy array, we can use a custom decoder function\n",
    "\n",
    "def custom_decoder(obj):\n",
    "    if '__tuple__' in obj:\n",
    "        return tuple(obj['items'])\n",
    "    elif '__ndarray__' in obj:\n",
    "        return np.array(obj['n_component'])\n",
    "    return obj\n",
    "\n",
    "with open(\"data/convex_TempTopP.json\", \"r\") as file:\n",
    "    dict_1_convex_json = json.load(file)\n",
    "\n",
    "# Convert tuples and NumPy arrays back to original format\n",
    "dict_1_convex_json = {key: (value[0], value[1]['n_component']) for key, value in dict_1_convex_json.items()}\n",
    "\n",
    "# we can clean it up further by summing all the values in the n_components to get the sum of information retained\n",
    "dict_1_convex_json = {key: (value[0], sum(value[1])) for key, value in dict_1_convex_json.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c3dcb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note order goes (TopP=0|Temperature=0, TopP=0.5|Temperature=0, TopP=1|Temperature=0, TopP=0|Temperature=1, TopP=0.5|Temperature=1, TopP=1|Temperature=1, TopP=0|Temperature=2, TopP=0.5|Temperature=2, Human 50 v1, Human 50 v2)\n",
      "\n",
      "data/ablation_tempTopP_froth.csv\n",
      "Percent difference for data/ablation_tempTopP_froth.csv:[-24, -25, -24, -25, -19, -8, -22, -24, 0, 0]\n",
      "data/ablation_tempTopP_towels.csv\n",
      "Percent difference for data/ablation_tempTopP_towels.csv:[-48, -42, -69, -48, -41, -20, -46, -33, 2, 0]\n",
      "data/ablation_tempTopP_time.csv\n",
      "Percent difference for data/ablation_tempTopP_time.csv:[-27, -27, -42, -30, -40, -20, -53, -43, 0, 0]\n",
      "data/ablation_tempTopP_powder.csv\n",
      "Percent difference for data/ablation_tempTopP_powder.csv:[-36, -25, -41, -22, -30, -5, -20, -50, 0, 0]\n",
      "data/ablation_tempTopP_exercise.csv\n",
      "Percent difference for data/ablation_tempTopP_exercise.csv:[-26, -28, -23, -16, -14, -6, -23, -14, -6, 0]\n"
     ]
    }
   ],
   "source": [
    "# DPP percent difference calculation\n",
    "percent_diff = {}\n",
    "for key, value in dict_1_DPP_json.items():\n",
    "    csv_file = key[0]\n",
    "    if csv_file not in percent_diff:\n",
    "        percent_diff[csv_file] = []\n",
    "    percent_diff[csv_file].append(value)\n",
    "\n",
    "print(\"Note order goes (TopP=0|Temperature=0, TopP=0.5|Temperature=0, TopP=1|Temperature=0, TopP=0|Temperature=1, TopP=0.5|Temperature=1, TopP=1|Temperature=1, TopP=0|Temperature=2, TopP=0.5|Temperature=2, Human 50 v1, Human 50 v2)\" )\n",
    "print(\"\")\n",
    "for csv_file, values in percent_diff.items():\n",
    "    percent_changes = percent_change(values)\n",
    "    print(csv_file)\n",
    "    print(f\"Percent difference for {csv_file}:{percent_changes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd4aeef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note order goes (TopP=0|Temperature=0, TopP=0.5|Temperature=0, TopP=1|Temperature=0, TopP=0|Temperature=1, TopP=0.5|Temperature=1, TopP=1|Temperature=1, TopP=0|Temperature=2, TopP=0.5|Temperature=2, Human 50 v1, Human 50 v2)\n",
      "\n",
      "Percent difference for data/ablation_tempTopP_froth.csv:[-18, -19, -19, -21, -20, -12, -15, -21, -2, 0]\n",
      "Percent difference for data/ablation_tempTopP_towels.csv:[-38, -38, -48, -36, -33, -24, -35, -31, 3, 0]\n",
      "Percent difference for data/ablation_tempTopP_time.csv:[-14, -14, -20, -18, -23, -16, -30, -22, 1, 0]\n",
      "Percent difference for data/ablation_tempTopP_powder.csv:[-26, -18, -27, -17, -19, -7, -16, -34, 0, 0]\n",
      "Percent difference for data/ablation_tempTopP_exercise.csv:[-9, -8, -7, -4, -5, -4, -7, -5, -2, 0]\n"
     ]
    }
   ],
   "source": [
    "# Nearest Generated Difference percent difference calculation\n",
    "percent_diff = {}\n",
    "for key, value in dict_1_nearest_json.items():\n",
    "    csv_file = key[0]\n",
    "    if csv_file not in percent_diff:\n",
    "        percent_diff[csv_file] = []\n",
    "    percent_diff[csv_file].append(value)\n",
    "\n",
    "print(\"Note order goes (TopP=0|Temperature=0, TopP=0.5|Temperature=0, TopP=1|Temperature=0, TopP=0|Temperature=1, TopP=0.5|Temperature=1, TopP=1|Temperature=1, TopP=0|Temperature=2, TopP=0.5|Temperature=2, Human 50 v1, Human 50 v2)\" )\n",
    "print(\"\")\n",
    "for csv_file, values in percent_diff.items():\n",
    "    percent_changes = percent_change(values)\n",
    "    print(f\"Percent difference for {csv_file}:{percent_changes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2292acb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note order goes (TopP=0|Temperature=0, TopP=0.5|Temperature=0, TopP=1|Temperature=0, TopP=0|Temperature=1, TopP=0.5|Temperature=1, TopP=1|Temperature=1, TopP=0|Temperature=2, TopP=0.5|Temperature=2, Human 50 v1, Human 50 v2)\n",
      "\n",
      "Percent difference for data/ablation_tempTopP_froth.csv:[-94, -94, -94, -96, -97, -88, -87, -97, -34, 0]\n",
      "Percent difference for data/ablation_tempTopP_towels.csv:[-100, -100, -100, -100, -100, -98, -100, -100, 26, 0]\n",
      "Percent difference for data/ablation_tempTopP_time.csv:[-93, -91, -96, -96, -98, -95, -99, -97, -12, 0]\n",
      "Percent difference for data/ablation_tempTopP_powder.csv:[-99, -96, -99, -94, -96, -72, -94, -100, 32, 0]\n",
      "Percent difference for data/ablation_tempTopP_exercise.csv:[-74, -68, -67, -37, -57, -46, -66, -63, -19, 0]\n"
     ]
    }
   ],
   "source": [
    "# Convex Hull percent difference calculation\n",
    "percent_diff = {}\n",
    "for key, value in dict_1_convex_json.items():\n",
    "    key = eval(key)\n",
    "    csv_file = key[0]\n",
    "    value1 = value[0]\n",
    "    if csv_file not in percent_diff:\n",
    "        percent_diff[csv_file] = []\n",
    "    percent_diff[csv_file].append(value1)\n",
    "\n",
    "print(\"Note order goes (TopP=0|Temperature=0, TopP=0.5|Temperature=0, TopP=1|Temperature=0, TopP=0|Temperature=1, TopP=0.5|Temperature=1, TopP=1|Temperature=1, TopP=0|Temperature=2, TopP=0.5|Temperature=2, Human 50 v1, Human 50 v2)\" )\n",
    "print(\"\")\n",
    "for csv_file, values in percent_diff.items():\n",
    "    percent_changes = percent_change(values)\n",
    "    print(f\"Percent difference for {csv_file}:{percent_changes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c784576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note order goes (TopP=0|Temperature=0, TopP=0.5|Temperature=0, TopP=1|Temperature=0, TopP=0|Temperature=1, TopP=0.5|Temperature=1, TopP=1|Temperature=1, TopP=0|Temperature=2, TopP=0.5|Temperature=2, Human 50 v1, Human 50 v2)\n",
      "\n",
      "Percent difference for data/ablation_tempTopP_froth.csv:[-17, -18, -18, -21, -22, -12, -12, -21, -3, 0]\n",
      "Percent difference for data/ablation_tempTopP_towels.csv:[-38, -40, -48, -36, -33, -27, -34, -33, 2, 0]\n",
      "Percent difference for data/ablation_tempTopP_time.csv:[-12, -13, -17, -18, -22, -17, -30, -21, 1, 0]\n",
      "Percent difference for data/ablation_tempTopP_powder.csv:[-26, -18, -27, -16, -18, -8, -17, -34, 1, 0]\n",
      "Percent difference for data/ablation_tempTopP_exercise.csv:[-5, -4, -3, -1, -3, -3, -3, -3, -1, 0]\n"
     ]
    }
   ],
   "source": [
    "# Centroid Distance percent difference calculation\n",
    "percent_diff = {}\n",
    "for key, value in dict_1_centroid_json.items():\n",
    "    csv_file = key[0]\n",
    "    if csv_file not in percent_diff:\n",
    "        percent_diff[csv_file] = []\n",
    "    percent_diff[csv_file].append(value)\n",
    "\n",
    "print(\"Note order goes (TopP=0|Temperature=0, TopP=0.5|Temperature=0, TopP=1|Temperature=0, TopP=0|Temperature=1, TopP=0.5|Temperature=1, TopP=1|Temperature=1, TopP=0|Temperature=2, TopP=0.5|Temperature=2, Human 50 v1, Human 50 v2)\" )\n",
    "print(\"\")\n",
    "for csv_file, values in percent_diff.items():\n",
    "    percent_changes = percent_change(values)\n",
    "    print(f\"Percent difference for {csv_file}:{percent_changes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5ae432",
   "metadata": {},
   "source": [
    "## RQ2:\n",
    "\n",
    "(1b) How does styling of the input prompt impact the output quality and diversity of the prompt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f3bbf488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of CSV files\n",
    "csv_files = [\n",
    "    'data/ablation_topic_towels.csv',\n",
    "    'data/ablation_topic_powder.csv',\n",
    "    'data/ablation_topic_time.csv',\n",
    "    'data/ablation_topic_exercise.csv',\n",
    "    'data/ablation_topic_froth.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "22055476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this only needs to be ran once.\n",
    "dict_2_DPP = {}\n",
    "dict_2_convex = {}\n",
    "dict_2_centroid = {}\n",
    "dict_2_nearest = {}\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    count = 0\n",
    "    for column in df.columns:\n",
    "        # encode the column text data into embeddings\n",
    "        embeddings = model.encode(df[column].astype(str).tolist())\n",
    "        # calculate the DPP\n",
    "        dict_2_DPP[(csv_file, count)] = DPP_diversity(embeddings, lambda0=0)\n",
    "        # calculate the convex hull\n",
    "        dict_2_convex[(csv_file, count)] = convexhull(embeddings, n_components = 13)\n",
    "        # calculate the distance to centroid\n",
    "        dict_2_centroid[(csv_file, count)] = distance_to_centroid(embeddings)\n",
    "        # calculate the nearest generated distance (average)\n",
    "        dict_2_nearest[(csv_file, count)] = gen_gen_distance(embeddings, reduction = \"ave\")\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2e0a847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DPP\n",
    "import json\n",
    "# convert tuples in dictionary to strings\n",
    "dict_2_DPP_str = {str(key): value for key, value in dict_2_DPP.items()}\n",
    "\n",
    "# convert float32 values to float\n",
    "dict_2_DPP_str = {key:float(value) for key, value in dict_2_DPP_str.items()}\n",
    "\n",
    "with open(\"data/DPP_Topics.json\", \"w\") as file:\n",
    "    json.dump(dict_2_DPP_str, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "52b4fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centroid Distance\n",
    "dict_2_centroid_str = {str(key): value for key, value in dict_2_centroid.items()}\n",
    "\n",
    "dict_2_centroid_str = {key:float(value) for key, value in dict_2_centroid_str.items()}\n",
    "\n",
    "with open(\"data/centroid_Topics.json\", \"w\") as file:\n",
    "    json.dump(dict_2_centroid_str, file)\n",
    "    \n",
    "# Nearest Generated Sample\n",
    "dict_2_nearest_str = {str(key): value for key, value in dict_2_nearest.items()}\n",
    "\n",
    "dict_2_nearest_str = {key:float(value) for key, value in dict_2_nearest_str.items()}\n",
    "\n",
    "with open(\"data/nearest_Topics.json\", \"w\") as file:\n",
    "    json.dump(dict_2_nearest_str, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "90438916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convex Hull\n",
    "def convert_to_json(obj):\n",
    "    if isinstance(obj, tuple):\n",
    "        return {'__tuple__': True, 'items': list(obj)}\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return {'__ndarray__': True, 'n_component': obj.tolist()}\n",
    "    return obj\n",
    "\n",
    "\n",
    "dict_2_convex_str = {str(key): value for key, value in dict_2_convex.items()}\n",
    "\n",
    "with open(\"data/convex_Topics.json\", \"w\") as file:\n",
    "    json.dump(dict_2_convex_str, file, default = convert_to_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1dca3b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to retrieve the json file\n",
    "with open(\"data/DPP_Topics.json\", \"r\") as file:\n",
    "    dict_2_DPP_json = json.load(file)\n",
    "dict_2_DPP_json = {eval(key): value for key, value in dict_2_DPP_json.items()}\n",
    "\n",
    "with open(\"data/centroid_Topics.json\", \"r\") as file:\n",
    "    dict_2_centroid_json = json.load(file)\n",
    "dict_2_centroid_json = {eval(key): value for key, value in dict_2_centroid_json.items()}\n",
    "\n",
    "with open(\"data/nearest_Topics.json\", \"r\") as file:\n",
    "    dict_2_nearest_json = json.load(file)\n",
    "dict_2_nearest_json = {eval(key): value for key, value in dict_2_nearest_json.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e1289f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert convex hull back to the original dictionary with tuples and numpy array, we can use a custom decoder function\n",
    "\n",
    "def custom_decoder(obj):\n",
    "    if '__tuple__' in obj:\n",
    "        return tuple(obj['items'])\n",
    "    elif '__ndarray__' in obj:\n",
    "        return np.array(obj['n_component'])\n",
    "    return obj\n",
    "\n",
    "with open(\"data/convex_Topics.json\", \"r\") as file:\n",
    "    dict_2_convex_json = json.load(file)\n",
    "\n",
    "# Convert tuples and NumPy arrays back to original format\n",
    "dict_2_convex_json = {key: (value[0], value[1]['n_component']) for key, value in dict_2_convex_json.items()}\n",
    "\n",
    "# we can clean it up further by summing all the values in the n_components to get the sum of information retained\n",
    "dict_2_convex_json = {key: (value[0], sum(value[1])) for key, value in dict_2_convex_json.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9c81e805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note order goes zero-shot, few-shot, novel, unique, creative, critique-critique, design-expert, farfetched, human-1, human-2\n",
      "\n",
      "Percent difference for data/ablation_topic_towels.csv:[20, 8, 13, 23, 1, 0, 21, 2, -2, 0]\n",
      "Percent difference for data/ablation_topic_powder.csv:[5, 16, 10, 10, 5, -4, 14, 0, 0, 0]\n",
      "Percent difference for data/ablation_topic_time.csv:[20, 8, 13, 16, 21, 14, 22, 25, 0, 0]\n",
      "Percent difference for data/ablation_topic_exercise.csv:[6, 6, 3, 10, 6, -1, 2, 3, 6, 0]\n",
      "Percent difference for data/ablation_topic_froth.csv:[8, 10, 6, 8, 7, 5, 8, 5, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# DPP percent difference calculation\n",
    "percent_diff = {}\n",
    "for key, value in dict_2_DPP_json.items():\n",
    "    csv_file = key[0]\n",
    "    if csv_file not in percent_diff:\n",
    "        percent_diff[csv_file] = []\n",
    "    percent_diff[csv_file].append(value)\n",
    "\n",
    "print(\"Note order goes zero-shot, few-shot, novel, unique, creative, critique-critique, design-expert, farfetched, human-1, human-2\")\n",
    "print(\"\")\n",
    "for csv_file, values in percent_diff.items():\n",
    "    percent_changes = percent_change(values)\n",
    "    print(f\"Percent difference for {csv_file}:{percent_changes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aff1fdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note order goes zero-shot, few-shot, novel, unique, creative, critique-critique, design-expert, farfetched, human-1, human-2\n",
      "\n",
      "Percent difference for data/ablation_topic_towels.csv:[-24, -15, -17, -24, -10, -8, -22, -9, 3, 0]\n",
      "Percent difference for data/ablation_topic_powder.csv:[-7, -11, -10, -10, -7, 1, -12, -4, 0, 0]\n",
      "Percent difference for data/ablation_topic_time.csv:[-16, -9, -11, -11, -16, -13, -17, -18, 1, 0]\n",
      "Percent difference for data/ablation_topic_exercise.csv:[-4, -4, -2, -5, -4, -1, -1, -4, -2, 0]\n",
      "Percent difference for data/ablation_topic_froth.csv:[-12, -13, -12, -11, -12, -9, -11, -9, -2, 0]\n"
     ]
    }
   ],
   "source": [
    "# Nearest percent difference calculation\n",
    "percent_diff = {}\n",
    "for key, value in dict_2_nearest_json.items():\n",
    "    csv_file = key[0]\n",
    "    if csv_file not in percent_diff:\n",
    "        percent_diff[csv_file] = []\n",
    "    percent_diff[csv_file].append(value)\n",
    "\n",
    "print(\"Note order goes zero-shot, few-shot, novel, unique, creative, critique-critique, design-expert, farfetched, human-1, human-2\")\n",
    "print(\"\")\n",
    "for csv_file, values in percent_diff.items():\n",
    "    percent_changes = percent_change(values)\n",
    "    print(f\"Percent difference for {csv_file}:{percent_changes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ca2f8b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note order goes zero-shot, few-shot, novel, unique, creative, critique-critique, design-expert, farfetched, human-1, human-2\n",
      "\n",
      "Percent difference for data/ablation_topic_towels.csv:[-98, -94, -95, -98, -84, -81, -97, -87, 26, 0]\n",
      "Percent difference for data/ablation_topic_powder.csv:[-72, -84, -77, -80, -77, -27, -85, -54, 32, 0]\n",
      "Percent difference for data/ablation_topic_time.csv:[-95, -84, -86, -86, -95, -92, -95, -96, -12, 0]\n",
      "Percent difference for data/ablation_topic_exercise.csv:[-46, -46, -45, -55, -54, -47, -37, -58, -19, 0]\n",
      "Percent difference for data/ablation_topic_froth.csv:[-88, -87, -87, -86, -90, -79, -78, -80, -34, 0]\n"
     ]
    }
   ],
   "source": [
    "# Convex Hull percent difference calculation\n",
    "percent_diff = {}\n",
    "for key, value in dict_2_convex_json.items():\n",
    "    key = eval(key)\n",
    "    csv_file = key[0]\n",
    "    value1 = value[0]\n",
    "    if csv_file not in percent_diff:\n",
    "        percent_diff[csv_file] = []\n",
    "    percent_diff[csv_file].append(value1)\n",
    "\n",
    "print(\"Note order goes zero-shot, few-shot, novel, unique, creative, critique-critique, design-expert, farfetched, human-1, human-2\")\n",
    "print(\"\")\n",
    "for csv_file, values in percent_diff.items():\n",
    "    percent_changes = percent_change(values)\n",
    "    print(f\"Percent difference for {csv_file}:{percent_changes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743864e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centroid Distance percent difference calculation\n",
    "percent_diff = {}\n",
    "for key, value in dict_2_centroid_json.items():\n",
    "    csv_file = key[0]\n",
    "    if csv_file not in percent_diff:\n",
    "        percent_diff[csv_file] = []\n",
    "    percent_diff[csv_file].append(value)\n",
    "\n",
    "print(\"Note order goes zero-shot, few-shot, novel, unique, creative, critique-critique, design-expert, farfetched, human-1, human-2\")\n",
    "print(\"\")\n",
    "for csv_file, values in percent_diff.items():\n",
    "    percent_changes = percent_change(values)\n",
    "    print(f\"Percent difference for {csv_file}:{percent_changes}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:research]",
   "language": "python",
   "name": "conda-env-research-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
